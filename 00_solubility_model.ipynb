{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubaidillah-chem/fouling-ml/blob/main/00_solubility_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "jnKje_G_7qxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v81NbVVc7mue"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "data = pd.read_csv(\"gdrive/MyDrive/Solubility.csv\")\n",
        "\n",
        "# Add jitter noise to MW and NBP (Simulating experimental variability)\n",
        "np.random.seed(123)\n",
        "data['MW'] += np.random.normal(0, 0.5, size=len(data))\n",
        "data['NBP'] += np.random.normal(0, 0.5, size=len(data))\n",
        "\n",
        "# Create matrix and target\n",
        "X = data.drop(columns=['O2solubility'])\n",
        "y = data['O2solubility']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=123\n",
        ")\n",
        "\n",
        "# Define hyperparameter search space\n",
        "space = [\n",
        "    Real(0.01, 0.3, name='eta'),\n",
        "    Integer(3, 10, name='max_depth'),\n",
        "    Real(0.5, 1.0, name='subsample'),\n",
        "    Real(0.5, 1.0, name='colsample_bytree'),\n",
        "]\n",
        "\n",
        "# Objective function for Bayesian Optimization\n",
        "@use_named_args(space)\n",
        "def objective(**params):\n",
        "    model = XGBRegressor(\n",
        "        objective='reg:squarederror',\n",
        "        eval_metric='rmse',\n",
        "        n_estimators=1000,\n",
        "        early_stopping_rounds=10,\n",
        "        verbosity=0,\n",
        "        random_state=123,\n",
        "        **params\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "        verbose=False\n",
        "    )\n",
        "    preds = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    return rmse\n",
        "\n",
        "# Run Bayesian Optimization\n",
        "result = gp_minimize(\n",
        "    objective,\n",
        "    space,\n",
        "    n_calls=30,\n",
        "    random_state=123\n",
        ")\n",
        "\n",
        "print(f\"Best RMSE: {result.fun:.4f}\")\n",
        "print(f\"Best parameters: {result.x}\")\n",
        "\n",
        "# Train final model with best parameters\n",
        "best_params = {\n",
        "    'eta': result.x[0],\n",
        "    'max_depth': result.x[1],\n",
        "    'subsample': result.x[2],\n",
        "    'colsample_bytree': result.x[3]\n",
        "}\n",
        "\n",
        "final_model = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    eval_metric='rmse',\n",
        "    n_estimators=1000,\n",
        "    early_stopping_rounds=10,\n",
        "    verbosity=1,\n",
        "    random_state=123,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "final_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "    verbose=100\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "preds = final_model.predict(X_test)\n",
        "rmse_final = np.sqrt(mean_squared_error(y_test, preds))\n",
        "print(f\"Final Test RMSE: {rmse_final:.4f}\")\n"
      ]
    }
  ]
}